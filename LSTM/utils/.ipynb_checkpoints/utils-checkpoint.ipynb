{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_data_seg(line):\n",
    "    return re.match('^\\.[a-z]{0,1}data', line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_text_seg(line):\n",
    "    return re.match('^\\.text', line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_2digit_hex(text):\n",
    "    return re.match('^[0-9A-F]{2}\\+?$', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_text_comment(text):\n",
    "    return re.match('^_[a-z]?text$', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_data_comment(text):\n",
    "    return re.match('^_[a-z]?data$', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_addr_label(text):\n",
    "    return True if re.match('^sub_[0-9A-F]{6}\\:?$', text) or re.match('^loc_[0-9A-F]{6}\\:?$', text) or re.match('^ds\\:{1}[a-zA-Z0-9]{1,}$', text) else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_num_value(text):\n",
    "    return True if ((text.endswith('h') and re.match('^[0-9A-F]{1,10}h$', text)) or re.match('^[0-9A-F]{1,10}$', text)) else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(file):\n",
    "    with open(file, 'r', encoding='ISO-8859-1') as f:\n",
    "        struct_dict = {\n",
    "            \"text_arr\": [],\n",
    "            \"file_name\": file\n",
    "        }\n",
    "        for asm_line in f:\n",
    "            asm_line = asm_line.strip()\n",
    "            if is_text_seg(asm_line):\n",
    "                struct_dict[\"text_arr\"].append(asm_line)\n",
    "            else:\n",
    "                continue\n",
    "        return struct_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def start_of_comment(arr):\n",
    "    indices = [ i for i, token in enumerate(arr) if token.startswith(';') ]\n",
    "    if len(indices) > 0:\n",
    "        return indices[0]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_commas(line_arr):\n",
    "    newlinearr = []\n",
    "    for line in line_arr:\n",
    "        newline = []\n",
    "        for token in line:\n",
    "            if ',' in token:\n",
    "                temp = token.split(',')\n",
    "                temp = [ item for item in temp if item != '' ]\n",
    "                for item in temp:\n",
    "                    newline.append(item)\n",
    "            else:\n",
    "                newline.append(token)\n",
    "        newlinearr.append(newline)\n",
    "    return newlinearr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanse_lines(line_arr, segment):\n",
    "    # Split by whitespace each line in line_arr\n",
    "    line_arr = [ line.split() for line in line_arr ]\n",
    "    # Remove all comments from each line (array)\n",
    "    line_arr = [ line[:(start_of_comment(line))] for line in line_arr ]\n",
    "    # Remove the first word (\".text*\" or \".*data*\") \n",
    "    # from each line (array), depending on whether \n",
    "    # they are data segment or text segment\n",
    "    if segment == 'text':\n",
    "        line_arr = [ [token for token in line if not is_text_seg(token)] for line in line_arr ]\n",
    "    else:\n",
    "        line_arr = [ [token for token in line if not is_data_seg(token)] for line in line_arr ]\n",
    "    # Remove hexadecimal numbers (purpose is to \n",
    "    # remove the first few hex numbers which probably \n",
    "    # is the hex representation of the opcodes)\n",
    "    line_arr = [ [token for token in line if not is_2digit_hex(token)] for line in line_arr ]\n",
    "    # Remove all '??' from line\n",
    "    line_arr = [ [token for token in line if not ('??' in token) ] for line in line_arr ]\n",
    "    # Split all tokens using ','\n",
    "    line_arr = remove_commas(line_arr)\n",
    "    # Remove all empty line (array).\n",
    "    line_arr = [ line for line in line_arr if line != [] ]\n",
    "    # Remove all db, dw, dd, dq, dt, ddq and do opcodes and their operands\n",
    "    # This is to help reduce the size of the dataset, and also since it \n",
    "    # only creates some variables\n",
    "    line_arr = [ line for line in line_arr if line[0] != 'db' or line[0] != 'dw' or line[0] != 'dd' or line[0] != 'dq' or line[0] != 'dt' or line[0] != 'ddq' or line[0] != 'do' ]\n",
    "    \n",
    "    line_arr = [ line for line in line_arr if not (re.match('^include', line[0]) or re.match('^\\.[0-9a-zA-Z]{1,}', line[0])) ]\n",
    "    return line_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def separate_symbols(symbol, line):\n",
    "    newline = []\n",
    "    for i, token in enumerate(line):\n",
    "        if symbol in token:\n",
    "            temp_arr = token.split(symbol)\n",
    "            for j in range(1, len(temp_arr), 2):\n",
    "                temp_arr.insert(j, symbol)\n",
    "            temp_arr = [ val for val in temp_arr if val ]\n",
    "            for val in temp_arr:\n",
    "                newline.append(val)\n",
    "        else:\n",
    "            newline.append(token)\n",
    "    return newline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
